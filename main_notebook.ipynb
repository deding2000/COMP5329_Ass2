{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8ec581",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from Dataload import pil_process_image_color, encode, CustomImageDataset\n",
    "from models import CNN\n",
    "from utils import test, train_network\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "lr = 0.0001\n",
    "\n",
    "# Set device to GPU if this is available\n",
    "use_cuda = True if torch.cuda.is_available() else False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('We are using GPU.' if use_cuda else 'We are using CPU.')\n",
    "\n",
    "# Loading filenames and labels\n",
    "# Assumes data is in folder \"Dataset\"\n",
    "DATASET_PATH = \"Dataset/\"\n",
    "FILENAME_TRAIN = 'train.csv'\n",
    "FILENAME_TEST = 'test.csv'\n",
    "\n",
    "with open(DATASET_PATH + FILENAME_TRAIN) as file:\n",
    "    lines = [re.sub(r'([^,])\"(\\s*[^\\n])', r'\\1/\"\\2', line) for line in file]\n",
    "    df_train = pd.read_csv(StringIO(''.join(lines)), escapechar=\"/\")\n",
    "with open(DATASET_PATH + FILENAME_TEST) as file:\n",
    "    lines = [re.sub(r'([^,])\"(\\s*[^\\n])', r'\\1/\"\\2', line) for line in file]\n",
    "    df_test = pd.read_csv(StringIO(''.join(lines)), escapechar=\"/\")\n",
    "df_train.to_csv(\"train_labels_captions.csv\")\n",
    "df_test.to_csv(\"test_labels_captions.csv\")\n",
    "\n",
    "# To get overview\n",
    "#print(df_test.describe)\n",
    "\n",
    "# Defining transforms\n",
    "INPUT_HEIGHT = 128\n",
    "INPUT_WIDTH = 128\n",
    "resize = transforms.Resize(size=(INPUT_HEIGHT,\n",
    "        INPUT_WIDTH)) # Trying to resize to (INPUT_HEIGHT,INPUT_WIDTH)\n",
    "\n",
    "# TODO: we can add data augmentation here\n",
    "# See for example https://pyimagesearch.com/2021/10/04/image-data-loaders-in-pytorch/\n",
    "# or here: https://docs.pytorch.org/vision/main/transforms.html \n",
    "trainTransforms = transforms.Compose(\n",
    "    [resize,transforms.RandomHorizontalFlip(),transforms.ToTensor()]) \n",
    "testTransforms = transforms.Compose([resize,transforms.ToTensor()]) \n",
    "\n",
    "# Create dataloaders\n",
    "training_data = CustomImageDataset(df_train,DATASET_PATH+\"data/\",transform=trainTransforms,target_transform=encode)\n",
    "test_data = CustomImageDataset(df_test,DATASET_PATH+\"data/\",transform=testTransforms,target_transform=encode)\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Display example of random image and label.\n",
    "print(\"Example of a single batch:\")\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch size: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "print(f\"Label: {label}\")\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.show()\n",
    "\n",
    "# Setup model\n",
    "model = CNN().to(device)\n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "print('Model initialized.')\n",
    "\n",
    "# Testing model on small subset of data\n",
    "subset_size = 200\n",
    "subset_indices = torch.randperm(len(training_data))[:subset_size]\n",
    "subset_data = Subset(training_data, range(0, subset_size,2)) #subset_indices\n",
    "subset_dataloader = DataLoader(subset_data, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "\n",
    "# Testing training\n",
    "log_interval = 2 # How often we print train loss\n",
    "train_network(log_interval,model, device, subset_dataloader, optimizer, loss,epochs=5)\n",
    "# Testing forward operator\n",
    "test(model, device, subset_dataloader, loss)\n",
    "print('Model works.')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
