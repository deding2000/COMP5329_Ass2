{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deding2000/COMP5329_Ass2/blob/main/main_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b8ec581",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b8ec581",
        "outputId": "cb5369c8-54c7-4f27-9350-188d6a4f4701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Not needed before we upload files to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get python files and augmented data"
      ],
      "metadata": {
        "id": "h-vEfJ6eKbdo"
      },
      "id": "h-vEfJ6eKbdo"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload() # select all python files from the github page and kaggle.json"
      ],
      "metadata": {
        "id": "GX_AvoqV4L6x",
        "outputId": "b995bfc2-7135-4108-9231-64b7dd3d952f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "GX_AvoqV4L6x",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0f67467a-4316-42bc-b757-c44c2e66a27d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0f67467a-4316-42bc-b757-c44c2e66a27d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best_samples_weight_full.pt to best_samples_weight_full.pt\n",
            "Saving best_samples_weight_subset.pt to best_samples_weight_subset.pt\n",
            "Saving compute_mean_std.py to compute_mean_std.py\n",
            "Saving Dataload.py to Dataload.py\n",
            "Saving F1_test.py to F1_test.py\n",
            "Saving image_sizes.py to image_sizes.py\n",
            "Saving kaggle.json to kaggle.json\n",
            "Saving main.py to main.py\n",
            "Saving main_notebook.ipynb to main_notebook.ipynb\n",
            "Saving main_notebook_rosa.ipynb to main_notebook_rosa.ipynb\n",
            "Saving metrics.py to metrics.py\n",
            "Saving metrics_each_class.py to metrics_each_class.py\n",
            "Saving models.py to models.py\n",
            "Saving NEW_weighted_sampler.py to NEW_weighted_sampler.py\n",
            "Saving norm_samples_weight_full.pt to norm_samples_weight_full.pt\n",
            "Saving norm_samples_weight_subset.pt to norm_samples_weight_subset.pt\n",
            "Saving README.md to README.md\n",
            "Saving requirements.txt to requirements.txt\n",
            "Saving rnn_test.ipynb to rnn_test.ipynb\n",
            "Saving samples_weight.pt to samples_weight.pt\n",
            "Saving samples_weight_subset.pt to samples_weight_subset.pt\n",
            "Saving stratified_split_creation.py to stratified_split_creation.py\n",
            "Saving subset_train_indices.npy to subset_train_indices.npy\n",
            "Saving test_labels_captions.csv to test_labels_captions.csv\n",
            "Saving text.py to text.py\n",
            "Saving train_labels_captions.csv to train_labels_captions.csv\n",
            "Saving unnorm_samples_weight_full.pt to unnorm_samples_weight_full.pt\n",
            "Saving unnorm_samples_weight_subset.pt to unnorm_samples_weight_subset.pt\n",
            "Saving utils.py to utils.py\n",
            "Saving validation_indices.npy to validation_indices.npy\n",
            "Saving weighted_sampler.py to weighted_sampler.py\n",
            "Saving weighted_sampler_subset.py to weighted_sampler_subset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get data from kaggle"
      ],
      "metadata": {
        "id": "cqBu7hBgKWcy"
      },
      "id": "cqBu7hBgKWcy"
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle competitions download -c 'multi-label-classification-competition-2025'\n",
        "! mkdir Dataset\n",
        "! unzip multi-label-classification-competition-2025.zip -d Dataset &> /dev/null"
      ],
      "metadata": {
        "id": "uf168JTBuHpQ",
        "outputId": "0eac6f16-b6bd-44d5-8417-981584c422b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "uf168JTBuHpQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading multi-label-classification-competition-2025.zip to /content\n",
            " 99% 396M/399M [00:00<00:00, 1.38GB/s]\n",
            "100% 399M/399M [00:00<00:00, 1.38GB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining model arcitechture - A CNN similar to AlexNet"
      ],
      "metadata": {
        "id": "0SEMqdSaMLju"
      },
      "id": "0SEMqdSaMLju"
    },
    {
      "cell_type": "code",
      "source": [
        "# Model arcitechture\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # Define convolutional kernels and number of kernels in each layer\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=8, stride=4, padding=0)\n",
        "        self.conv2 = nn.Conv2d(64,128, 5, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128,192, 3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(192,192,3, stride=1,padding=1)\n",
        "        self.conv5 = nn.Conv2d(192,128,3, stride=1,padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(3,stride=2)\n",
        "        self.pool2 = nn.MaxPool2d(3,stride=2)\n",
        "        self.pool3 = nn.MaxPool2d(3,stride=2)\n",
        "        self.bn1 = nn.BatchNorm2d(16*2*2)\n",
        "        self.bn2 = nn.BatchNorm2d(32*2*2)\n",
        "        self.bn3 = nn.BatchNorm2d(192)\n",
        "        self.bn4 = nn.BatchNorm2d(192)\n",
        "        self.bn5 = nn.BatchNorm2d(128)\n",
        "        self.bn6 = nn.BatchNorm1d(150)\n",
        "        self.bn7 = nn.BatchNorm1d(64)\n",
        "        self.dropout1 = nn.Dropout2d(0.2)\n",
        "        self.dropout2 = nn.Dropout2d(0.2)\n",
        "        self.dropout3 = nn.Dropout(0.5)\n",
        "        self.dropout4 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(4608,150)\n",
        "        self.fc2 = nn.Linear(150,64)\n",
        "        self.fc3 = nn.Linear(64,18)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
        "        #x = self.dropout1(x)\n",
        "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
        "        #x = self.dropout2(x)\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.pool3(F.relu(self.bn5(self.conv5(x))))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = self.dropout3(x)\n",
        "        x = F.relu(self.bn6(self.fc1(x)))\n",
        "        x = self.dropout4(x)\n",
        "        x = F.relu(self.bn7(self.fc2(x)))\n",
        "        logits = self.fc3(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "u6SWXu0b-joR"
      },
      "id": "u6SWXu0b-joR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup dataloaders and initialize model"
      ],
      "metadata": {
        "id": "S4rX7whL7SR3"
      },
      "id": "S4rX7whL7SR3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading relevant packages\n",
        "import re\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Subset, random_split, WeightedRandomSampler\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "import zipfile\n",
        "# Custom made modules\n",
        "from Dataload import pil_process_image_color, encode, Dataset, CustomImageDataset\n",
        "from utils import train_network, pos_weight, test\n",
        "from metrics import compute_metrics\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "lr = 0.003\n",
        "weight_decay = 0\n",
        "INPUT_HEIGHT = 256\n",
        "INPUT_WIDTH = 256\n",
        "\n",
        "# Techniques for handling class imbalance\n",
        "Normalize_weights = True # To use normalized class weights or not\n",
        "use_weighted_sampler = False # To use weighted sampling or not\n",
        "use_weighted_loss = False # To use weighed loss function or not\n",
        "aug_all = False #augment all or add more augmentation to non-class 1 datapoints\n",
        "\n",
        "# Set device to GPU if this is available\n",
        "use_cuda = True if torch.cuda.is_available() else False\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('We are using GPU.' if use_cuda else 'We are using CPU.')\n",
        "\n",
        "# Loading filenames and labels\n",
        "DATASET_PATH = \"/content/Dataset/COMP5329S1A2Dataset/\"\n",
        "FILENAME_TRAIN = 'train.csv'\n",
        "FILENAME_TEST = 'test.csv'\n",
        "FILENAME_TRAIN_AUG = 'train_aug.csv' # augmented data for training\n",
        "\n",
        "# Unzip extra data\n",
        "# zip_path= DATASET_PATH + \"SUBSET_augmented_images.zip\"\n",
        "# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "#     zip_ref.extractall(\"data/\")\n",
        "# zip_path= DATASET_PATH + \"FULL_augmented_images.zip\"\n",
        "\n",
        "my_dir = r\"/content/Dataset/COMP5329S1A2Dataset/data/\"\n",
        "my_zip = r\"/content/Dataset/COMP5329S1A2Dataset/FULL_augmented_images.zip\"\n",
        "\n",
        "with zipfile.ZipFile(my_zip) as zip_file:\n",
        "    for member in zip_file.namelist():\n",
        "        filename = os.path.basename(member)\n",
        "        # skip directories\n",
        "        if not filename:\n",
        "            continue\n",
        "\n",
        "        # copy file (taken from zipfile's extract)\n",
        "        source = zip_file.open(member)\n",
        "        target = open(os.path.join(my_dir, filename), \"wb\")\n",
        "        with source, target:\n",
        "            shutil.copyfileobj(source, target)\n",
        "\n",
        "\n",
        "with open(DATASET_PATH + FILENAME_TRAIN) as file:\n",
        "    lines = [re.sub(r'([^,])\"(\\s*[^\\n])', r'\\1/\"\\2', line) for line in file]\n",
        "    df_train = pd.read_csv(StringIO(''.join(lines)), escapechar=\"/\")\n",
        "with open(DATASET_PATH + FILENAME_TEST) as file:\n",
        "    lines = [re.sub(r'([^,])\"(\\s*[^\\n])', r'\\1/\"\\2', line) for line in file]\n",
        "    df_test = pd.read_csv(StringIO(''.join(lines)), escapechar=\"/\")\n",
        "df_train.to_csv(\"train_labels_captions.csv\")\n",
        "df_test.to_csv(\"test_labels_captions.csv\")\n",
        "df_train_bigger = pd.read_csv(\"/content/Dataset/COMP5329S1A2Dataset/train_aug.csv\")\n",
        "\n",
        "# Defining transforms\n",
        "resize = transforms.Resize(size=(INPUT_HEIGHT,\n",
        "        INPUT_WIDTH)) # For resizing images to square\n",
        "\n",
        "# Data augmentation\n",
        "trainTransforms_augment = transforms.Compose(\n",
        "    [resize,transforms.RandomHorizontalFlip(),transforms.RandomAffine(degrees=30),\n",
        "     transforms.ColorJitter(),transforms.RandomCrop(size=256,pad_if_needed=True),\n",
        "     transforms.RandomApply([transforms.GaussianBlur(3)], p=0.5),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=[0.3598, 0.3480, 0.3270], std=[0.1929, 0.1884, 0.1901])])\n",
        "\n",
        "if aug_all:\n",
        "    trainTransforms_basic = trainTransforms_augment\n",
        "else:\n",
        "# Transform to use on common class\n",
        "  trainTransforms_basic = transforms.Compose(\n",
        "      [resize,transforms.ColorJitter(),transforms.RandomCrop(size=256,pad_if_needed=True),\n",
        "     transforms.ToTensor()\n",
        "      ,transforms.Normalize(mean=[0.3598, 0.3480, 0.3270], std=[0.1929, 0.1884, 0.1901])])\n",
        "      #AddGaussianNoise(mean=0., std=0.1)])\n",
        "\n",
        "# Transform for test images\n",
        "testTransforms = transforms.Compose([resize,transforms.ToTensor(),\n",
        "                                     transforms.Normalize(mean=[0.4652, 0.4492, 0.4214], std=[0.2317, 0.2265, 0.2303])])\n",
        "\n",
        "# Sampling method\n",
        "if Normalize_weights:\n",
        "  # Calculate weights for loss function\n",
        "  c_weights = pos_weight(df_train,barplot=False,normalize=True)\n",
        "  samples_weight = torch.load(\"/content/norm_samples_weight_full.pt\") # Sample common class less\n",
        "else:\n",
        "  c_weights = pos_weight(df_train,barplot=False,normalize=False)\n",
        "  samples_weight = torch.load(\"/content/unnorm_samples_weight_full.pt\") # Sample common class less\n",
        "\n",
        "weighted_sampler_full = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
        "\n",
        "# Create dataloaders\n",
        "training_data = CustomImageDataset(df_train_bigger,DATASET_PATH+\"data/\",transform=trainTransforms_basic,transform_aug=trainTransforms_augment,target_transform=encode)\n",
        "test_data = CustomImageDataset(df_test,DATASET_PATH+\"data/\",transform=testTransforms,target_transform=None,targets_available=False)\n",
        "if use_weighted_sampler:\n",
        "  train_dataloader = DataLoader(training_data, batch_size=batch_size, sampler=weighted_sampler_full)\n",
        "else:\n",
        "  train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(test_data,shuffle=False)\n",
        "\n",
        "# Setup model\n",
        "model = CNN().to(device)\n",
        "\n",
        "# Use BCE loss\n",
        "if use_weighted_loss:\n",
        "  loss = torch.nn.BCEWithLogitsLoss(c_weights.to(device))\n",
        "else:\n",
        "  loss = torch.nn.BCEWithLogitsLoss()\n",
        "# Use Adam optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "print('Model initialized.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hae78mIgE9gh",
        "outputId": "9559e3d1-3673-4eba-affc-f5a3714f74a1"
      },
      "id": "hae78mIgE9gh",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We are using GPU.\n",
            "Class counts: tensor([22794.,  1162.,  4364.,  1272.,  1130.,  1394.,  1221.,  2210.,  1042.,\n",
            "         1471.,   604.,   605.,   251.,  1934.,  1099.,  1430.,  1525.,  1020.],\n",
            "       dtype=torch.float64)\n",
            "Class weights: tensor([0.0110, 0.2160, 0.0575, 0.1973, 0.2221, 0.1801, 0.2056, 0.1136, 0.2409,\n",
            "        0.1706, 0.4156, 0.4149, 1.0000, 0.1298, 0.2284, 0.1755, 0.1646, 0.2461],\n",
            "       dtype=torch.float64)\n",
            "Model initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training on subset of all data and compute metrics for validation set"
      ],
      "metadata": {
        "id": "07arXwUC7tSn"
      },
      "id": "07arXwUC7tSn"
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading indices for 80/20 split of training data\n",
        "train_idx = np.load(\"/content/subset_train_indices.npy\")\n",
        "validation_idx = np.load(\"/content/validation_indices.npy\")\n",
        "\n",
        "# Loading sample weights to sample some classes more than others\n",
        "\n",
        "if Normalize_weights:\n",
        "  samples_weight_subset = torch.load(\"/content/norm_samples_weight_subset.pt\")\n",
        "else:\n",
        "  samples_weight_subset = torch.load(\"/content/unnorm_samples_weight_subset.pt\") # Sample common class less\n",
        "\n",
        "weigthed_sampler_subset = WeightedRandomSampler(samples_weight_subset,len(samples_weight_subset))\n",
        "\n",
        "# Subset dataset for train and val\n",
        "subset_train_dataset = Subset(training_data, train_idx)\n",
        "validation_dataset = Subset(training_data, validation_idx)\n",
        "if use_weighted_sampler:\n",
        "  subset_train_loader = DataLoader(subset_train_dataset, batch_size=batch_size,sampler=weigthed_sampler_subset)\n",
        "else:\n",
        "  subset_train_loader = DataLoader(subset_train_dataset, batch_size=batch_size,shuffle=True)\n",
        "\n",
        "validation_loader = DataLoader(validation_dataset, shuffle=False)\n",
        "\n",
        "# Training\n",
        "log_interval = 50 # How often we print train loss\n",
        "train_losses, test_losses = train_network(log_interval,model, device, subset_train_loader, validation_loader,optimizer, loss,epochs=10)\n",
        "\n",
        "plt.figure(figsize=(15,4))\n",
        "plt.plot(train_losses,label=\"Training\")\n",
        "plt.plot(test_losses,label=\"Validation\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "# Set thresholds for predictions\n",
        "thresholds = [0.5]*18\n",
        "\n",
        "# Testing on validation set and compute metrics\n",
        "print(\"With prediction_all = True:\")\n",
        "test_loss, all_preds, all_targets = test(model, device, validation_loader, loss, thresholds=thresholds, target_available=True,predict_all=True) # output predictions as tensors\n",
        "all_preds = np.asarray([tensor.cpu().numpy().squeeze() for tensor in all_preds])\n",
        "all_targets = np.asarray([tensor.cpu().numpy().squeeze() for tensor in all_targets])\n",
        "#for label in range(1,19): # remember that 12 is deleted!\n",
        "#   print(\"Metrics for class {}\".format(label))\n",
        "#   print(compute_metrics(all_preds.squeeze()[:,label-1],all_targets.squeeze()[:,label-1]))\n",
        "print(\"Full Metrics\")\n",
        "print(compute_metrics(all_preds,all_targets))\n",
        "\n",
        "# print(\"With prediction_all = False:\")\n",
        "# test_loss, all_preds, all_targets = test(model, device, validation_loader, loss, thresholds=thresholds, target_available=True,predict_all=False) # output predictions as tensors\n",
        "# all_preds = np.asarray([tensor.cpu().numpy().squeeze() for tensor in all_preds])\n",
        "# all_targets = np.asarray([tensor.cpu().numpy().squeeze() for tensor in all_targets])\n",
        "# print(\"Full Metrics\")\n",
        "# print(compute_metrics(all_preds,all_targets))"
      ],
      "metadata": {
        "id": "6-ZRv7f47QJO",
        "outputId": "ec237673-bfad-44af-e1e9-c592b1eb85d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        }
      },
      "id": "6-ZRv7f47QJO",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 0 [0/23996 (0%)]\tLoss: 0.759397\n",
            "\n",
            "Train Epoch: 0 [3200/23996 (13%)]\tLoss: 0.181407\n",
            "\n",
            "Train Epoch: 0 [6400/23996 (27%)]\tLoss: 0.180577\n",
            "\n",
            "Train Epoch: 0 [9600/23996 (40%)]\tLoss: 0.177570\n",
            "\n",
            "Train Epoch: 0 [12800/23996 (53%)]\tLoss: 0.177348\n",
            "\n",
            "Train Epoch: 0 [16000/23996 (67%)]\tLoss: 0.138144\n",
            "\n",
            "Train Epoch: 0 [19200/23996 (80%)]\tLoss: 0.194618\n",
            "\n",
            "Train Epoch: 0 [22400/23996 (93%)]\tLoss: 0.188564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [01:59<17:56, 119.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set results: Average loss: 0.1553, F1 Score: 0.64\n",
            "\n",
            "Train Epoch: 1 [0/23996 (0%)]\tLoss: 0.195257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [02:03<18:34, 123.84s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-e7c50a56be09>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;31m# How often we print train loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/utils.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(log_interval, model, device, train_loader, test_loader, optimizer, loss, thresholds, epochs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mtest_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_available\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/utils.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(log_interval, model, device, train_loader, optimizer, epoch, loss_func)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Iterate through the entire dataset to form an epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Train for an iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Dataload.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_aug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# if self.use_caption:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \"\"\"\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Anti-alias option is always applied for PIL Image input. Argument antialias is ignored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Got inappropriate size arg: {size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2314\u001b[0m                 )\n\u001b[1;32m   2315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2316\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2318\u001b[0m     def reduce(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Prediction on training set with prediction_all = True:\")\n",
        "test_loss, all_preds, all_targets = test(model, device, subset_train_loader, loss, thresholds=thresholds, target_available=True,predict_all=False) # output predictions as tensors\n",
        "all_preds = np.asarray([tensor.cpu().numpy().squeeze() for tensor in all_preds])\n",
        "all_targets = np.asarray([tensor.cpu().numpy().squeeze() for tensor in all_targets])\n",
        "#for label in range(1,19): # remember that 12 is deleted!\n",
        "#   print(\"Metrics for class {}\".format(label))\n",
        "#   print(compute_metrics(all_preds.squeeze()[:,label-1],all_targets.squeeze()[:,label-1]))"
      ],
      "metadata": {
        "id": "VE3doxTz6FaQ",
        "outputId": "78e423be-d7ce-4aa4-ab89-915c4f697962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "id": "VE3doxTz6FaQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction on training set with prediction_all = True:\n",
            "\n",
            "Test set results: Average loss: 0.0925, F1 Score: 0.87\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (375,) + inhomogeneous part.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-d9bf8bc9aab9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prediction on training set with prediction_all = True:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_available\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredict_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# output predictions as tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mall_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_preds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mall_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_targets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#for label in range(1,19): # remember that 12 is deleted!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (375,) + inhomogeneous part."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuning of thresholds"
      ],
      "metadata": {
        "id": "moQlI6T8PnZw"
      },
      "id": "moQlI6T8PnZw"
    },
    {
      "cell_type": "code",
      "source": [
        "threshold_values = [0.55,0.5,0.45,0.4,0.35,0.3]\n",
        "thresholds = [0.5]*18\n",
        "best_thresholds = []\n",
        "for label in range(1,19): # remember that class 12 is deleted!\n",
        "    print(\"Searching for label {}\".format(label))\n",
        "    best_F1 = 0\n",
        "    for idx in tqdm(range(len(threshold_values))):\n",
        "        thresholds[label-1] = threshold_values[idx]\n",
        "        _, all_preds, all_targets = test(model, device, validation_loader, loss, thresholds=thresholds, target_available=True) # output predictions as tensors\n",
        "        all_preds = np.asarray([pred.cpu() for pred in all_preds])\n",
        "        all_targets = np.asarray([targ.cpu() for targ in all_targets])\n",
        "        F1_score = compute_metrics(all_preds,all_targets)[\"F1_score\"]\n",
        "        if F1_score > best_F1:\n",
        "            best_F1 = F1_score\n",
        "            best_threshold = threshold_values[idx]\n",
        "            best_thresholds.append(best_threshold)\n",
        "    print(\"Found best F1: {}\".format(best_F1))\n",
        "    print(\"Found best threshold {}\".format(best_threshold))\n",
        "    thresholds[label-1] = best_threshold\n",
        "print(\"Final Thresholds = {}\".format(thresholds))"
      ],
      "metadata": {
        "id": "ZYeDI6XS2gBo",
        "outputId": "754c7a2d-3b6c-4be0-ca33-f27a8664e5d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "id": "ZYeDI6XS2gBo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for label 2\n",
            "Found best F1: 0.663791884631698\n",
            "Found best threshold 0.35\n",
            "Searching for label 3\n",
            "Found best F1: 0.6667128987517337\n",
            "Found best threshold 0.3\n",
            "Searching for label 4\n",
            "Found best F1: 0.6674057649667406\n",
            "Found best threshold 0.4\n",
            "Searching for label 5\n",
            "Found best F1: 0.6662981898576759\n",
            "Found best threshold 0.45\n",
            "Searching for label 6\n",
            "Found best F1: 0.6675383662514623\n",
            "Found best threshold 0.3\n",
            "Searching for label 7\n",
            "Found best F1: 0.667125740256163\n",
            "Found best threshold 0.5\n",
            "Searching for label 8\n",
            "Found best F1: 0.6689636163175302\n",
            "Found best threshold 0.4\n",
            "Searching for label 9\n",
            "Found best F1: 0.6685509444367848\n",
            "Found best threshold 0.3\n",
            "Searching for label 10\n",
            "Found best F1: 0.6677197802197802\n",
            "Found best threshold 0.35\n",
            "Searching for label 11\n",
            "Found best F1: 0.6664835542127308\n",
            "Found best threshold 0.4\n",
            "Searching for label 12\n",
            "Found best F1: 0.6675839295542102\n",
            "Found best threshold 0.4\n",
            "Searching for label 13\n",
            "Found best F1: 0.6680423717155042\n",
            "Found best threshold 0.4\n",
            "Searching for label 14\n",
            "Found best F1: 0.6670334961139005\n",
            "Found best threshold 0.45\n",
            "Searching for label 15\n",
            "Found best F1: 0.6668964566386323\n",
            "Found best threshold 0.35\n",
            "Searching for label 16\n",
            "Found best F1: 0.6668044646548159\n",
            "Found best threshold 0.45\n",
            "Searching for label 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-71-bcc6e729e3f2>\", line 10, in <cell line: 0>\n",
            "    _, all_preds, all_targets = test(model, device, validation_loader, loss, thresholds=thresholds, target_available=True) # output predictions as tensors\n",
            "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-62-e17ac7eb4db6>\", line 20, in test\n",
            "    for data, target in (test_loader):  # Iterate through the entire test set.\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 708, in __next__\n",
            "    data = self._next_data()\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 764, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 50, in fetch\n",
            "    data = self.dataset.__getitems__(possibly_batched_index)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\", line 420, in __getitems__\n",
            "    return [self.dataset[self.indices[idx]] for idx in indices]\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\", line 420, in <listcomp>\n",
            "    return [self.dataset[self.indices[idx]] for idx in indices]\n",
            "            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Dataload.py\", line 61, in __getitem__\n",
            "    image = self.transform_aug(image)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n",
            "    img = t(img)\n",
            "          ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\", line None, in forward\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1686, in getframeinfo\n",
            "    start = lineno - 1 - context//2\n",
            "            ~~~~~~~^~~\n",
            "TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-71-bcc6e729e3f2>\", line 10, in <cell line: 0>\n",
            "    _, all_preds, all_targets = test(model, device, validation_loader, loss, thresholds=thresholds, target_available=True) # output predictions as tensors\n",
            "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-62-e17ac7eb4db6>\", line 20, in test\n",
            "    for data, target in (test_loader):  # Iterate through the entire test set.\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 708, in __next__\n",
            "    data = self._next_data()\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 764, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 50, in fetch\n",
            "    data = self.dataset.__getitems__(possibly_batched_index)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\", line 420, in __getitems__\n",
            "    return [self.dataset[self.indices[idx]] for idx in indices]\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\", line 420, in <listcomp>\n",
            "    return [self.dataset[self.indices[idx]] for idx in indices]\n",
            "            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Dataload.py\", line 61, in __getitem__\n",
            "    image = self.transform_aug(image)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n",
            "    img = t(img)\n",
            "          ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\", line None, in forward\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "           ^^^^^^^^^^^^\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1686, in getframeinfo\n",
            "    start = lineno - 1 - context//2\n",
            "            ~~~~~~~^~~\n",
            "TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-71-bcc6e729e3f2>\", line 10, in <cell line: 0>\n",
            "    _, all_preds, all_targets = test(model, device, validation_loader, loss, thresholds=thresholds, target_available=True) # output predictions as tensors\n",
            "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-62-e17ac7eb4db6>\", line 20, in test\n",
            "    for data, target in (test_loader):  # Iterate through the entire test set.\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 708, in __next__\n",
            "    data = self._next_data()\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 764, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 50, in fetch\n",
            "    data = self.dataset.__getitems__(possibly_batched_index)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\", line 420, in __getitems__\n",
            "    return [self.dataset[self.indices[idx]] for idx in indices]\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\", line 420, in <listcomp>\n",
            "    return [self.dataset[self.indices[idx]] for idx in indices]\n",
            "            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Dataload.py\", line 61, in __getitem__\n",
            "    image = self.transform_aug(image)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n",
            "    img = t(img)\n",
            "          ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\", line None, in forward\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "           ^^^^^^^^^^^^\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n",
            "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "           ^^^^^^^^^^^^\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1686, in getframeinfo\n",
            "    start = lineno - 1 - context//2\n",
            "            ~~~~~~~^~~\n",
            "TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check model size and save temporary model"
      ],
      "metadata": {
        "id": "ro9KmOX_70BV"
      },
      "id": "ro9KmOX_70BV"
    },
    {
      "cell_type": "code",
      "source": [
        "# save model, scores and plot and check size of model is under 100MB\n",
        "model_name = \"test\"\n",
        "\n",
        "path_name_model = \"/content/model_\" + model_name+\".pt\"\n",
        "path_name_plot = \"/content/model_\" + model_name + \"_losscurve.png\"\n",
        "path_name_scores = \"/content/model_\" + model_name + \"_scores.txt\"\n",
        "\n",
        "torch.save(model.state_dict(), path_name_model)\n",
        "print(f\"Model saved to {path_name_model}\")\n",
        "size_mb = os.path.getsize(path_name_model) / (1024 * 1024)\n",
        "print(f\"Model size: {size_mb} MB\")\n",
        "\n",
        "plt.figure(figsize=(15,4))\n",
        "plt.plot(train_losses,label=\"Training\")\n",
        "plt.plot(test_losses,label=\"Validation\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.savefig(path_name_plot)\n",
        "\n",
        "import json\n",
        "with open(path_name_scores, 'w') as file:\n",
        "     file.write(json.dumps(compute_metrics(all_preds,all_targets)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "yI8gKgxvU0Tr",
        "outputId": "c6ecdb78-d68d-4fc7-ad8b-a97615d2e0f2"
      },
      "id": "yI8gKgxvU0Tr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/model_test.pt\n",
            "Model size: 6.491914749145508 MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model on entire training set and compute predictions"
      ],
      "metadata": {
        "id": "BgfkwggB794G"
      },
      "id": "BgfkwggB794G"
    },
    {
      "cell_type": "code",
      "source": [
        "# Training new model on the full dataset\n",
        "model_full = CNN().to(device)\n",
        "c_weights_full = c_weights.to(device)\n",
        "loss_full = torch.nn.BCEWithLogitsLoss() #c_weights_full)\n",
        "optimizer_full = torch.optim.Adam(model_full.parameters(), lr=lr)\n",
        "print('Full Model initialized.')\n",
        "log_interval = 50 # How often we print train loss\n",
        "train_losses_full = train_network(log_interval,model_full, device, train_dataloader, test_loader=0,optimizer=optimizer_full, loss=loss_full,epochs=1)\n",
        "\n",
        "plt.figure(figsize=(15,4))\n",
        "plt.plot(train_losses_full,label=\"Training\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "# Compute predictions for true test set\n",
        "thresholds_full = [0.5]*18\n",
        "test_pred_full = test(model_full, device, test_dataloader,loss_full,thresholds=thresholds_full,target_available=False,predict_all=True)\n",
        "test_pred_full_predict_all_false = test(model_full, device, test_dataloader,loss_full,thresholds=thresholds_full,target_available=False,predict_all=False)"
      ],
      "metadata": {
        "id": "YgDEmbblCdgS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 954
        },
        "outputId": "4ac844ae-19de-41d7-b3a9-1106bb9ab24f"
      },
      "id": "YgDEmbblCdgS",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Model initialized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 0 [0/45918 (0%)]\tLoss: 0.715955\n",
            "\n",
            "Train Epoch: 0 [3200/45918 (7%)]\tLoss: 0.222785\n",
            "\n",
            "Train Epoch: 0 [6400/45918 (14%)]\tLoss: 0.190000\n",
            "\n",
            "Train Epoch: 0 [9600/45918 (21%)]\tLoss: 0.199190\n",
            "\n",
            "Train Epoch: 0 [12800/45918 (28%)]\tLoss: 0.220684\n",
            "\n",
            "Train Epoch: 0 [16000/45918 (35%)]\tLoss: 0.198755\n",
            "\n",
            "Train Epoch: 0 [19200/45918 (42%)]\tLoss: 0.178076\n",
            "\n",
            "Train Epoch: 0 [22400/45918 (49%)]\tLoss: 0.217027\n",
            "\n",
            "Train Epoch: 0 [25600/45918 (56%)]\tLoss: 0.203907\n",
            "\n",
            "Train Epoch: 0 [28800/45918 (63%)]\tLoss: 0.220263\n",
            "\n",
            "Train Epoch: 0 [32000/45918 (70%)]\tLoss: 0.207786\n",
            "\n",
            "Train Epoch: 0 [35200/45918 (77%)]\tLoss: 0.225812\n",
            "\n",
            "Train Epoch: 0 [38400/45918 (84%)]\tLoss: 0.193681\n",
            "\n",
            "Train Epoch: 0 [41600/45918 (91%)]\tLoss: 0.216708\n",
            "\n",
            "Train Epoch: 0 [44800/45918 (97%)]\tLoss: 0.160595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [02:33<00:00, 153.34s/it]\n",
            "100%|██████████| 10000/10000 [00:47<00:00, 209.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predictions computed for test set.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:46<00:00, 217.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predictions computed for test set.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABOMAAAFzCAYAAAB8Rs05AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAMuNJREFUeJzt3Xt0VuWBL/5vAiYImBBACWgUW51KrYKCUFo91TEDtrNqvS1bqoIuV63HS0+lziDTCqjT4aLHUovFM3ZaV6c6OLbacWyLF8ROqyl4YPAu4+lSQCGgY0kUBCJ5f3/4M23KRUCyg/L5rLUXeZ/97OcSfNYr3/XsvctKpVIpAAAAAECHK+/sAQAAAADA3kIYBwAAAAAFEcYBAAAAQEGEcQAAAABQEGEcAAAAABREGAcAAAAABRHGAQAAAEBBhHEAAAAAUJCunT2AD6rW1tasXLky++23X8rKyjp7OAAAAAB0klKplDfeeCMDBgxIefn2974J43bRypUrU1dX19nDAAAAAGAPsWLFihx00EHbrSOM20X77bdfknd+yVVVVZ08GgAAAAA6S3Nzc+rq6tryou0Rxu2id29NraqqEsYBAAAAsEOPMvMCBwAAAAAoiDAOAAAAAAoijAMAAACAgnhmHAAAAMAeolQq5e23387mzZs7eyj8mX322SddunR53+0I4wAAAAD2AJs2bcqqVauyfv36zh4KW1FWVpaDDjooPXv2fF/tCOMAAAAAOllra2tefPHFdOnSJQMGDEhFRcUOvZmTYpRKpbz66qt5+eWXc/jhh7+vHXLCOAAAAIBOtmnTprS2tqauri7du3fv7OGwFfvvv39eeumltLS0vK8wzgscAAAAAPYQ5eWimj3V7tqp6G8YAAAAAAoijAMAAACAggjjAAAAANijDBw4MDNnztzh+o888kjKysqydu3aDhvT7iKMAwAAAGCXlJWVbfeYMmXKLrX7+OOP56KLLtrh+p/61KeyatWqVFdX71J/RfI2VQAAAAB2yapVq9p+vvPOOzNp0qQsXbq0raxnz55tP5dKpWzevDldu753HLX//vvv1DgqKipSW1u7U9d0FjvjAAAAAPZApVIp6ze93SlHqVTaoTHW1ta2HdXV1SkrK2v7/Pzzz2e//fbLr371qwwdOjSVlZX57W9/m9///vf5whe+kH79+qVnz5457rjj8tBDD7Vr989vUy0rK8sPfvCDnH766enevXsOP/zw3HvvvW3n//w21dtuuy29evXK/fffn0GDBqVnz5455ZRT2oWHb7/9dr72ta+lV69e6dOnTyZMmJBx48bltNNO2+W/sx1hZxwAAADAHuitls35+KT7O6XvZ68dne4Vuyc2uuqqq3LDDTfkIx/5SGpqarJixYp87nOfy7e//e1UVlbmxz/+cT7/+c9n6dKlOfjgg7fZzjXXXJMZM2bk+uuvz/e+972cc845WbZsWXr37r3V+uvXr88NN9yQf/7nf055eXnOPffcXHnllbn99tuTJNOnT8/tt9+eH/3oRxk0aFC++93v5uc//3lOOumk3TLvbbEzDgAAAIAOc+211+av/uqv8tGPfjS9e/fO4MGD89WvfjWf+MQncvjhh+e6667LRz/60XY73bbm/PPPz5gxY3LYYYflH/7hH/Lmm29m4cKF26zf0tKSW265JcOGDcuxxx6byy67LPPmzWs7/73vfS8TJ07M6aefniOOOCKzZs1Kr169dte0t8nOOAAAAIA90L77dMmz147utL53l2HDhrX7/Oabb2bKlCn5xS9+kVWrVuXtt9/OW2+9leXLl2+3naOPPrrt5x49eqSqqipr1qzZZv3u3bvnox/9aNvn/v37t9VvamrK6tWrM3z48LbzXbp0ydChQ9Pa2rpT89tZe8TOuJtvvjkDBw5Mt27dMmLEiO2mmrfeemtOOOGE1NTUpKamJvX19e3qt7S0ZMKECTnqqKPSo0ePDBgwIGPHjs3KlSvbtTNw4MAt3vAxbdq0DpsjAAAAwM4oKytL94qunXKUlZXttnn06NGj3ecrr7wy99xzT/7hH/4hv/nNb7JkyZIcddRR2bRp03bb2Weffbb4/WwvONta/R19Fl5H6vQw7s4778z48eMzefLkLF68OIMHD87o0aO3mWw+8sgjGTNmTObPn5+GhobU1dVl1KhReeWVV5K8cz/w4sWLc/XVV2fx4sW5++67s3Tp0px66qlbtHXttddm1apVbcfll1/eoXMFAAAA2Ns9+uijOf/883P66afnqKOOSm1tbV566aVCx1BdXZ1+/frl8ccfbyvbvHlzFi9e3OF9d/ptqjfeeGO+8pWv5IILLkiS3HLLLfnFL36RH/7wh7nqqqu2qP/uQ/be9YMf/CA/+9nPMm/evIwdOzbV1dV58MEH29WZNWtWhg8fnuXLl7d7EOB+++33gXntLQAAAMCHweGHH5677747n//851NWVparr766w28N3ZrLL788U6dOzWGHHZYjjjgi3/ve9/KHP/xht+4K3JpO3Rm3adOmLFq0KPX19W1l5eXlqa+vT0NDww61sX79+rS0tGzzzRnJO/cBl5WVbfEQvmnTpqVPnz455phjcv311+ftt9/eZhsbN25Mc3NzuwMAAACAnXPjjTempqYmn/rUp/L5z38+o0ePzrHHHlv4OCZMmJAxY8Zk7NixGTlyZHr27JnRo0enW7duHdpvWakTb5ZduXJlDjzwwDz22GMZOXJkW/nf/u3f5te//nUWLFjwnm1ccskluf/++/PMM89s9Ze1YcOGfPrTn84RRxzRblfdjTfemGOPPTa9e/fOY489lokTJ+aCCy7IjTfeuNV+pkyZkmuuuWaL8qamplRVVe3IdAEAAAC2asOGDXnxxRdz6KGHdngYxNa1trZm0KBBOfvss3PddddtcX57f0fNzc2prq7eoZyo029TfT+mTZuWOXPm5JFHHtnqf6gtLS05++yzUyqVMnv27Hbnxo8f3/bz0UcfnYqKinz1q1/N1KlTU1lZuUVbEydObHdNc3Nz6urqduNsAAAAACjKsmXL8sADD+Qzn/lMNm7cmFmzZuXFF1/Ml7/85Q7tt1PDuL59+6ZLly5ZvXp1u/LVq1e/57PcbrjhhkybNi0PPfRQu1fbvuvdIG7ZsmV5+OGH3zOVHDFiRN5+++289NJL+djHPrbF+crKyq2GdAAAAAB88JSXl+e2227LlVdemVKplE984hN56KGHMmjQoA7tt1PDuIqKigwdOjTz5s3LaaedluSdLYHz5s3LZZddts3rZsyYkW9/+9u5//77M2zYsC3OvxvEvfDCC5k/f3769OnznmNZsmRJysvLc8ABB+zyfAAAAAD4YKirq8ujjz5aeL+dfpvq+PHjM27cuAwbNizDhw/PzJkzs27dura3q44dOzYHHnhgpk6dmiSZPn16Jk2alDvuuCMDBw5MY2NjkqRnz57p2bNnWlpactZZZ2Xx4sW57777snnz5rY6vXv3TkVFRRoaGrJgwYKcdNJJ2W+//dLQ0JArrrgi5557bmpqajrnFwEAAADAh16nh3Ff/OIX8+qrr2bSpElpbGzMkCFDMnfu3PTr1y9Jsnz58pSX//Glr7Nnz86mTZty1llntWtn8uTJmTJlSl555ZXce++9SZIhQ4a0qzN//vyceOKJqayszJw5czJlypRs3Lgxhx56aK644op2z4QDAAAAKFonvmeT97C7/m469W2qH2Q785YMAAAAgO3ZvHlz/uu//isHHHDADj1ui+I1NTVl5cqVOeyww7LPPvu0O7fXvE0VAAAA4MOgS5cu6dWrV9asWZMk6d69e8rKyjp5VLyrtbU1r776arp3756uXd9fnCaMAwAAANgD1NbWJklbIMeepby8PAcffPD7DkmFcQAAAAB7gLKysvTv3z8HHHBAWlpaOns4/JmKiop27zXYVcI4AAAAgD1Ily5d0qVLl84eBh3k/cd5AAAAAMAOEcYBAAAAQEGEcQAAAABQEGEcAAAAABREGAcAAAAABRHGAQAAAEBBhHEAAAAAUBBhHAAAAAAURBgHAAAAAAURxgEAAABAQYRxAAAAAFAQYRwAAAAAFEQYBwAAAAAFEcYBAAAAQEGEcQAAAABQEGEcAAAAABREGAcAAAAABRHGAQAAAEBBhHEAAAAAUBBhHAAAAAAURBgHAAAAAAURxgEAAABAQYRxAAAAAFAQYRwAAAAAFEQYBwAAAAAFEcYBAAAAQEGEcQAAAABQEGEcAAAAABREGAcAAAAABRHGAQAAAEBBhHEAAAAAUBBhHAAAAAAURBgHAAAAAAURxgEAAABAQYRxAAAAAFAQYRwAAAAAFEQYBwAAAAAFEcYBAAAAQEGEcQAAAABQEGEcAAAAABREGAcAAAAABRHGAQAAAEBBhHEAAAAAUBBhHAAAAAAURBgHAAAAAAURxgEAAABAQYRxAAAAAFAQYRwAAAAAFEQYBwAAAAAFEcYBAAAAQEH2iDDu5ptvzsCBA9OtW7eMGDEiCxcu3GbdW2+9NSeccEJqampSU1OT+vr6dvVbWloyYcKEHHXUUenRo0cGDBiQsWPHZuXKle3aef3113POOeekqqoqvXr1yoUXXpg333yzw+YIAAAAAJ0ext15550ZP358Jk+enMWLF2fw4MEZPXp01qxZs9X6jzzySMaMGZP58+enoaEhdXV1GTVqVF555ZUkyfr167N48eJcffXVWbx4ce6+++4sXbo0p556art2zjnnnDzzzDN58MEHc9999+U//uM/ctFFF3X4fAEAAADYe5WVSqVSZw5gxIgROe644zJr1qwkSWtra+rq6nL55Zfnqquues/rN2/enJqamsyaNStjx47dap3HH388w4cPz7Jly3LwwQfnueeey8c//vE8/vjjGTZsWJJk7ty5+dznPpeXX345AwYMeM9+m5ubU11dnaamplRVVe3EjAEAAAD4MNmZnKhTd8Zt2rQpixYtSn19fVtZeXl56uvr09DQsENtrF+/Pi0tLendu/c26zQ1NaWsrCy9evVKkjQ0NKRXr15tQVyS1NfXp7y8PAsWLNhqGxs3bkxzc3O7AwAAAAB2RqeGca+99lo2b96cfv36tSvv169fGhsbd6iNCRMmZMCAAe0CvT+1YcOGTJgwIWPGjGlLJhsbG3PAAQe0q9e1a9f07t17m/1OnTo11dXVbUddXd0OjQ8AAAAA3tXpz4x7P6ZNm5Y5c+bknnvuSbdu3bY439LSkrPPPjulUimzZ89+X31NnDgxTU1NbceKFSveV3sAAAAA7H26dmbnffv2TZcuXbJ69ep25atXr05tbe12r73hhhsybdq0PPTQQzn66KO3OP9uELds2bI8/PDD7e7Xra2t3eIFEW+//XZef/31bfZbWVmZysrKHZ0aAAAAAGyhU3fGVVRUZOjQoZk3b15bWWtra+bNm5eRI0du87oZM2bkuuuuy9y5c9s99+1d7wZxL7zwQh566KH06dOn3fmRI0dm7dq1WbRoUVvZww8/nNbW1owYMWI3zAwAAAAAttSpO+OSZPz48Rk3blyGDRuW4cOHZ+bMmVm3bl0uuOCCJMnYsWNz4IEHZurUqUmS6dOnZ9KkSbnjjjsycODAtme89ezZMz179kxLS0vOOuusLF68OPfdd182b97cVqd3796pqKjIoEGDcsopp+QrX/lKbrnllrS0tOSyyy7Ll770pR16kyoAAAAA7IpOD+O++MUv5tVXX82kSZPS2NiYIUOGZO7cuW0vdVi+fHnKy/+4gW/27NnZtGlTzjrrrHbtTJ48OVOmTMkrr7ySe++9N0kyZMiQdnXmz5+fE088MUly++2357LLLsvJJ5+c8vLynHnmmbnppps6bqIAAAAA7PXKSqVSqbMH8UHU3Nyc6urqNDU1tXseHQAAAAB7l53JiT7Qb1MFAAAAgA8SYRwAAAAAFEQYBwAAAAAFEcYBAAAAQEGEcQAAAABQEGEcAAAAABREGAcAAAAABRHGAQAAAEBBhHEAAAAAUBBhHAAAAAAURBgHAAAAAAURxgEAAABAQYRxAAAAAFAQYRwAAAAAFEQYBwAAAAAFEcYBAAAAQEGEcQAAAABQEGEcAAAAABREGAcAAAAABRHGAQAAAEBBhHEAAAAAUBBhHAAAAAAURBgHAAAAAAURxgEAAABAQYRxAAAAAFAQYRwAAAAAFEQYBwAAAAAFEcYBAAAAQEGEcQAAAABQEGEcAAAAABREGAcAAAAABRHGAQAAAEBBhHEAAAAAUBBhHAAAAAAURBgHAAAAAAURxgEAAABAQYRxAAAAAFAQYRwAAAAAFEQYBwAAAAAFEcYBAAAAQEGEcQAAAABQEGEcAAAAABREGAcAAAAABRHGAQAAAEBBhHEAAAAAUBBhHAAAAAAUZJfCuBUrVuTll19u+7xw4cJ8/etfzz/+4z/utoEBAAAAwIfNLoVxX/7ylzN//vwkSWNjY/7qr/4qCxcuzDe/+c1ce+21u3WAAAAAAPBhsUth3NNPP53hw4cnSf71X/81n/jEJ/LYY4/l9ttvz2233bY7xwcAAAAAHxq7FMa1tLSksrIySfLQQw/l1FNPTZIcccQRWbVq1e4bHQAAAAB8iOxSGHfkkUfmlltuyW9+85s8+OCDOeWUU5IkK1euTJ8+fXbrAAEAAADgw2KXwrjp06fn//yf/5MTTzwxY8aMyeDBg5Mk9957b9vtqwAAAABAe2WlUqm0Kxdu3rw5zc3NqampaSt76aWX0r179xxwwAG7bYB7qubm5lRXV6epqSlVVVWdPRwAAAAAOsnO5ES7tDPurbfeysaNG9uCuGXLlmXmzJlZunTpXhHEAQAAAMCu2KUw7gtf+EJ+/OMfJ0nWrl2bESNG5H//7/+d0047LbNnz96ptm6++eYMHDgw3bp1y4gRI7Jw4cJt1r311ltzwgknpKamJjU1Namvr9+i/t13351Ro0alT58+KSsry5IlS7Zo58QTT0xZWVm74+KLL96pcQMAAADAztqlMG7x4sU54YQTkiQ//elP069fvyxbtiw//vGPc9NNN+1wO3feeWfGjx+fyZMnZ/HixRk8eHBGjx6dNWvWbLX+I488kjFjxmT+/PlpaGhIXV1dRo0alVdeeaWtzrp163L88cdn+vTp2+37K1/5SlatWtV2zJgxY4fHDQAAAAC7ouuuXLR+/frst99+SZIHHnggZ5xxRsrLy/PJT34yy5Yt2+F2brzxxnzlK1/JBRdckCS55ZZb8otf/CI//OEPc9VVV21R//bbb2/3+Qc/+EF+9rOfZd68eRk7dmyS5LzzzkvyzvPrtqd79+6pra3d4bECAAAAwPu1SzvjDjvssPz85z/PihUrcv/992fUqFFJkjVr1uzwyww2bdqURYsWpb6+/o+DKS9PfX19GhoadqiN9evXp6WlJb17997pOdx+++3p27dvPvGJT2TixIlZv379TrcBAAAAADtjl3bGTZo0KV/+8pdzxRVX5C//8i8zcuTIJO/skjvmmGN2qI3XXnstmzdvTr9+/dqV9+vXL88///wOtTFhwoQMGDCgXaC3I7785S/nkEMOyYABA/Lkk09mwoQJWbp0ae6+++5tXrNx48Zs3Lix7XNzc/NO9QkAAAAAuxTGnXXWWTn++OOzatWqDB48uK385JNPzumnn77bBrc906ZNy5w5c/LII4+kW7duO3XtRRdd1PbzUUcdlf79++fkk0/O73//+3z0ox/d6jVTp07NNddc877GDAAAAMDebZduU02S2traHHPMMVm5cmVefvnlJMnw4cNzxBFH7ND1ffv2TZcuXbJ69ep25atXr37PZ7ndcMMNmTZtWh544IEcffTRuzaBPzFixIgkyf/7f/9vm3UmTpyYpqamtmPFihXvu18AAAAA9i67FMa1trbm2muvTXV1dQ455JAccsgh6dWrV6677rq0trbuUBsVFRUZOnRo5s2b167defPmtd32ujUzZszIddddl7lz52bYsGG7MvwtLFmyJEnSv3//bdaprKxMVVVVuwMAAAAAdsYu3ab6zW9+M//0T/+UadOm5dOf/nSS5Le//W2mTJmSDRs25Nvf/vYOtTN+/PiMGzcuw4YNy/DhwzNz5sysW7eu7e2qY8eOzYEHHpipU6cmSaZPn55JkybljjvuyMCBA9PY2Jgk6dmzZ3r27Jkkef3117N8+fKsXLkySbJ06dIk7+zkq62tze9///vccccd+dznPpc+ffrkySefzBVXXJH/8T/+x27ZZQcAAAAA21JWKpVKO3vRgAEDcsstt+TUU09tV/5v//ZvueSSS/LKK6/scFuzZs3K9ddfn8bGxgwZMiQ33XRT222jJ554YgYOHJjbbrstSTJw4MAsW7ZsizYmT56cKVOmJEluu+22tjBva3VWrFiRc889N08//XTWrVuXurq6nH766fnWt761U7vdmpubU11dnaamJrvkAAAAAPZiO5MT7VIY161btzz55JP5i7/4i3blS5cuzZAhQ/LWW2/tbJMfOMI4AAAAAJKdy4l26ZlxgwcPzqxZs7YonzVrlls9AQAAAGAbdumZcTNmzMhf//Vf56GHHmp72UJDQ0NWrFiRX/7yl7t1gAAAAADwYbFLO+M+85nP5L/+679y+umnZ+3atVm7dm3OOOOMPPPMM/nnf/7n3T1GAAAAAPhQ2KVnxm3LE088kWOPPTabN2/eXU3usTwzDgAAAICkgGfGAQAAAAA7TxgHAAAAAAURxgEAAABAQXbqbapnnHHGds+vXbv2/YwFAAAAAD7UdiqMq66ufs/zY8eOfV8DAgAAAIAPq50K4370ox911DgAAAAA4EPPM+MAAAAAoCDCOAAAAAAoiDAOAAAAAAoijAMAAACAggjjAAAAAKAgwjgAAAAAKIgwDgAAAAAKIowDAAAAgIII4wAAAACgIMI4AAAAACiIMA4AAAAACiKMAwAAAICCCOMAAAAAoCDCOAAAAAAoiDAOAAAAAAoijAMAAACAggjjAAAAAKAgwjgAAAAAKIgwDgAAAAAKIowDAAAAgIII4wAAAACgIMI4AAAAACiIMA4AAAAACiKMAwAAAICCCOMAAAAAoCDCOAAAAAAoiDAOAAAAAAoijAMAAACAggjjAAAAAKAgwjgAAAAAKIgwDgAAAAAKIowDAAAAgIII4wAAAACgIMI4AAAAACiIMA4AAAAACiKMAwAAAICCCOMAAAAAoCDCOAAAAAAoiDAOAAAAAAoijAMAAACAggjjAAAAAKAgwjgAAAAAKIgwDgAAAAAKIowDAAAAgIJ0ehh38803Z+DAgenWrVtGjBiRhQsXbrPurbfemhNOOCE1NTWpqalJfX39FvXvvvvujBo1Kn369ElZWVmWLFmyRTsbNmzIpZdemj59+qRnz54588wzs3r16t09NQAAAABop1PDuDvvvDPjx4/P5MmTs3jx4gwePDijR4/OmjVrtlr/kUceyZgxYzJ//vw0NDSkrq4uo0aNyiuvvNJWZ926dTn++OMzffr0bfZ7xRVX5N///d9z11135de//nVWrlyZM844Y7fPDwAAAAD+VFmpVCp1VucjRozIcccdl1mzZiVJWltbU1dXl8svvzxXXXXVe16/efPm1NTUZNasWRk7dmy7cy+99FIOPfTQ/Od//meGDBnSVt7U1JT9998/d9xxR84666wkyfPPP59BgwaloaEhn/zkJ3do7M3Nzamurk5TU1Oqqqp2cMYAAAAAfNjsTE7UaTvjNm3alEWLFqW+vv6PgykvT319fRoaGnaojfXr16elpSW9e/fe4X4XLVqUlpaWdv0eccQROfjgg3e4XwAAAADYFV07q+PXXnstmzdvTr9+/dqV9+vXL88///wOtTFhwoQMGDCgXbD2XhobG1NRUZFevXpt0W9jY+M2r9u4cWM2btzY9rm5uXmH+wQAAACAZA94gcOumjZtWubMmZN77rkn3bp16/D+pk6dmurq6rajrq6uw/sEAAAA4MOl08K4vn37pkuXLlu8xXT16tWpra3d7rU33HBDpk2blgceeCBHH330TvVbW1ubTZs2Ze3atTvV78SJE9PU1NR2rFixYqf6BQAAAIBOC+MqKioydOjQzJs3r62stbU18+bNy8iRI7d53YwZM3Lddddl7ty5GTZs2E73O3To0Oyzzz7t+l26dGmWL1++3X4rKytTVVXV7gAAAACAndFpz4xLkvHjx2fcuHEZNmxYhg8fnpkzZ2bdunW54IILkiRjx47NgQcemKlTpyZJpk+fnkmTJuWOO+7IwIED257x1rNnz/Ts2TNJ8vrrr2f58uVZuXJlkneCtuSdHXG1tbWprq7OhRdemPHjx6d3796pqqrK5ZdfnpEjR+7wm1QBAAAAYFd0ahj3xS9+Ma+++momTZqUxsbGDBkyJHPnzm17qcPy5ctTXv7HzXuzZ8/Opk2bctZZZ7VrZ/LkyZkyZUqS5N57720L85LkS1/60hZ1vvOd76S8vDxnnnlmNm7cmNGjR+f73/9+B84UAAAAAJKyUqlU6uxBfBA1Nzenuro6TU1NblkFAAAA2IvtTE70gX2bKgAAAAB80AjjAAAAAKAgwjgAAAAAKIgwDgAAAAAKIowDAAAAgIII4wAAAACgIMI4AAAAACiIMA4AAAAACiKMAwAAAICCCOMAAAAAoCDCOAAAAAAoiDAOAAAAAAoijAMAAACAggjjAAAAAKAgwjgAAAAAKIgwDgAAAAAKIowDAAAAgIII4wAAAACgIMI4AAAAACiIMA4AAAAACiKMAwAAAICCCOMAAAAAoCDCOAAAAAAoiDAOAAAAAAoijAMAAACAggjjAAAAAKAgwjgAAAAAKIgwDgAAAAAKIowDAAAAgIII4wAAAACgIMI4AAAAACiIMA4AAAAACiKMAwAAAICCCOMAAAAAoCDCOAAAAAAoiDAOAAAAAAoijAMAAACAggjjAAAAAKAgwjgAAAAAKIgwDgAAAAAKIowDAAAAgIII4wAAAACgIMI4AAAAACiIMA4AAAAACiKMAwAAAICCCOMAAAAAoCDCOAAAAAAoiDAOAAAAAAoijAMAAACAggjjAAAAAKAgwjgAAAAAKIgwDgAAAAAKIowDAAAAgIII4wAAAACgIMI4AAAAACjIHhHG3XzzzRk4cGC6deuWESNGZOHChduse+utt+aEE05ITU1NampqUl9fv0X9UqmUSZMmpX///tl3331TX1+fF154oV2dgQMHpqysrN0xbdq0DpkfAAAAACR7QBh35513Zvz48Zk8eXIWL16cwYMHZ/To0VmzZs1W6z/yyCMZM2ZM5s+fn4aGhtTV1WXUqFF55ZVX2urMmDEjN910U2655ZYsWLAgPXr0yOjRo7Nhw4Z2bV177bVZtWpV23H55Zd36FwBAAAA2LuVlUqlUmcOYMSIETnuuOMya9asJElra2vq6upy+eWX56qrrnrP6zdv3pyamprMmjUrY8eOTalUyoABA/KNb3wjV155ZZKkqakp/fr1y2233ZYvfelLSd7ZGff1r389X//613dp3M3Nzamurk5TU1Oqqqp2qQ0AAAAAPvh2Jifq1J1xmzZtyqJFi1JfX99WVl5envr6+jQ0NOxQG+vXr09LS0t69+6dJHnxxRfT2NjYrs3q6uqMGDFiizanTZuWPn365Jhjjsn111+ft99+e5v9bNy4Mc3Nze0OAAAAANgZXTuz89deey2bN29Ov3792pX369cvzz///A61MWHChAwYMKAtfGtsbGxr48/bfPdcknzta1/Lsccem969e+exxx7LxIkTs2rVqtx4441b7Wfq1Km55pprdnhuAAAAAPDnOjWMe7+mTZuWOXPm5JFHHkm3bt126trx48e3/Xz00UenoqIiX/3qVzN16tRUVlZuUX/ixIntrmlubk5dXd2uDx4AAACAvU6n3qbat2/fdOnSJatXr25Xvnr16tTW1m732htuuCHTpk3LAw88kKOPPrqt/N3rdrbNESNG5O23385LL7201fOVlZWpqqpqdwAAAADAzujUMK6ioiJDhw7NvHnz2spaW1szb968jBw5cpvXzZgxI9ddd13mzp2bYcOGtTt36KGHpra2tl2bzc3NWbBgwXbbXLJkScrLy3PAAQe8jxkBAAAAwLZ1+m2q48ePz7hx4zJs2LAMHz48M2fOzLp163LBBRckScaOHZsDDzwwU6dOTZJMnz49kyZNyh133JGBAwe2PQeuZ8+e6dmzZ8rKyvL1r389f//3f5/DDz88hx56aK6++uoMGDAgp512WpKkoaEhCxYsyEknnZT99tsvDQ0NueKKK3LuueempqamU34PAAAAAHz4dXoY98UvfjGvvvpqJk2alMbGxgwZMiRz585tewHD8uXLU17+xw18s2fPzqZNm3LWWWe1a2fy5MmZMmVKkuRv//Zvs27dulx00UVZu3Ztjj/++MydO7ftuXKVlZWZM2dOpkyZko0bN+bQQw/NFVdc0e6ZcAAAAACwu5WVSqVSZw/ig6i5uTnV1dVpamry/DgAAACAvdjO5ESd+sw4AAAAANibCOMAAAAAoCDCOAAAAAAoiDAOAAAAAAoijAMAAACAggjjAAAAAKAgwjgAAAAAKIgwDgAAAAAKIowDAAAAgIII4wAAAACgIMI4AAAAACiIMA4AAAAACiKMAwAAAICCCOMAAAAAoCDCOAAAAAAoSNfOHsAHValUSpI0Nzd38kgAAAAA6Ezv5kPv5kXbI4zbRW+88UaSpK6urpNHAgAAAMCe4I033kh1dfV265SVdiSyYwutra1ZuXJl9ttvv5SVlXX2cNhLNDc3p66uLitWrEhVVVVnDwc+0Kwn2D2sJdg9rCXYfawnOkOpVMobb7yRAQMGpLx8+0+FszNuF5WXl+eggw7q7GGwl6qqqvKlAruJ9QS7h7UEu4e1BLuP9UTR3mtH3Lu8wAEAAAAACiKMAwAAAICCCOPgA6SysjKTJ09OZWVlZw8FPvCsJ9g9rCXYPawl2H2sJ/Z0XuAAAAAAAAWxMw4AAAAACiKMAwAAAICCCOMAAAAAoCDCOAAAAAAoiDAO9jCvv/56zjnnnFRVVaVXr1658MIL8+abb273mg0bNuTSSy9Nnz590rNnz5x55plZvXr1Vuv+93//dw466KCUlZVl7dq1HTAD2DN0xFp64oknMmbMmNTV1WXffffNoEGD8t3vfrejpwKFu/nmmzNw4MB069YtI0aMyMKFC7db/6677soRRxyRbt265aijjsovf/nLdudLpVImTZqU/v37Z9999019fX1eeOGFjpwC7BF251pqaWnJhAkTctRRR6VHjx4ZMGBAxo4dm5UrV3b0NKDT7e7vpT918cUXp6ysLDNnztzNo4ZtE8bBHuacc87JM888kwcffDD33Xdf/uM//iMXXXTRdq+54oor8u///u+566678utf/zorV67MGWecsdW6F154YY4++uiOGDrsUTpiLS1atCgHHHBAfvKTn+SZZ57JN7/5zUycODGzZs3q6OlAYe68886MHz8+kydPzuLFizN48OCMHj06a9as2Wr9xx57LGPGjMmFF16Y//zP/8xpp52W0047LU8//XRbnRkzZuSmm27KLbfckgULFqRHjx4ZPXp0NmzYUNS0oHC7ey2tX78+ixcvztVXX53Fixfn7rvvztKlS3PqqacWOS0oXEd8L73rnnvuye9+97sMGDCgo6cB7ZWAPcazzz5bSlJ6/PHH28p+9atflcrKykqvvPLKVq9Zu3ZtaZ999indddddbWXPPfdcKUmpoaGhXd3vf//7pc985jOlefPmlZKU/vCHP3TIPKCzdfRa+lOXXHJJ6aSTTtp9g4dONnz48NKll17a9nnz5s2lAQMGlKZOnbrV+meffXbpr//6r9uVjRgxovTVr361VCqVSq2traXa2trS9ddf33Z+7dq1pcrKytK//Mu/dMAMYM+wu9fS1ixcuLCUpLRs2bLdM2jYA3XUWnr55ZdLBx54YOnpp58uHXLIIaXvfOc7u33ssC12xsEepKGhIb169cqwYcPayurr61NeXp4FCxZs9ZpFixalpaUl9fX1bWVHHHFEDj744DQ0NLSVPfvss7n22mvz4x//OOXllj4fbh25lv5cU1NTevfuvfsGD51o06ZNWbRoUbt1UF5envr6+m2ug4aGhnb1k2T06NFt9V988cU0Nja2q1NdXZ0RI0Zsd23BB1lHrKWtaWpqSllZWXr16rVbxg17mo5aS62trTnvvPPyN3/zNznyyCM7ZvCwHf5FDnuQxsbGHHDAAe3Kunbtmt69e6exsXGb11RUVGzxP2H9+vVru2bjxo0ZM2ZMrr/++hx88MEdMnbYk3TUWvpzjz32WO688873vP0VPihee+21bN68Of369WtXvr110NjYuN367/65M23CB11HrKU/t2HDhkyYMCFjxoxJVVXV7hk47GE6ai1Nnz49Xbt2zde+9rXdP2jYAcI4KMBVV12VsrKy7R7PP/98h/U/ceLEDBo0KOeee26H9QFF6Oy19KeefvrpfOELX8jkyZMzatSoQvoEgOSdlzmcffbZKZVKmT17dmcPBz5QFi1alO9+97u57bbbUlZW1tnDYS/VtbMHAHuDb3zjGzn//PO3W+cjH/lIamtrt3gQ6dtvv53XX389tbW1W72utrY2mzZtytq1a9vt6Fm9enXbNQ8//HCeeuqp/PSnP03yzlvtkqRv37755je/mWuuuWYXZwbF6uy19K5nn302J598ci666KJ861vf2qW5wJ6ob9++6dKlyxZv5N7aOnhXbW3tduu/++fq1avTv3//dnWGDBmyG0cPe46OWEvvejeIW7ZsWR5++GG74vhQ64i19Jvf/CZr1qxpd8fQ5s2b841vfCMzZ87MSy+9tHsnAVthZxwUYP/9988RRxyx3aOioiIjR47M2rVrs2jRorZrH3744bS2tmbEiBFbbXvo0KHZZ599Mm/evLaypUuXZvny5Rk5cmSS5Gc/+1meeOKJLFmyJEuWLMkPfvCDJO98EV166aUdOHPYvTp7LSXJM888k5NOOinjxo3Lt7/97Y6bLHSCioqKDB06tN06aG1tzbx589qtgz81cuTIdvWT5MEHH2yrf+ihh6a2trZdnebm5ixYsGCbbcIHXUespeSPQdwLL7yQhx56KH369OmYCcAeoiPW0nnnnZcnn3yy7d9GS5YsyYABA/I3f/M3uf/++ztuMvCnOvsNEkB7p5xySumYY44pLViwoPTb3/62dPjhh5fGjBnTdv7ll18ufexjHystWLCgreziiy8uHXzwwaWHH3649H//7/8tjRw5sjRy5Mht9jF//nxvU+VDryPW0lNPPVXaf//9S+eee25p1apVbceaNWsKnRt0pDlz5pQqKytLt912W+nZZ58tXXTRRaVevXqVGhsbS6VSqXTeeeeVrrrqqrb6jz76aKlr166lG264ofTcc8+VJk+eXNpnn31KTz31VFudadOmlXr16lX6t3/7t9KTTz5Z+sIXvlA69NBDS2+99Vbh84Oi7O61tGnTptKpp55aOuigg0pLlixp9z20cePGTpkjFKEjvpf+nLepUjRhHOxh/vu//7s0ZsyYUs+ePUtVVVWlCy64oPTGG2+0nX/xxRdLSUrz589vK3vrrbdKl1xySammpqbUvXv30umnn15atWrVNvsQxrE36Ii1NHny5FKSLY5DDjmkwJlBx/ve975XOvjgg0sVFRWl4cOHl373u9+1nfvMZz5TGjduXLv6//qv/1r6i7/4i1JFRUXpyCOPLP3iF79od761tbV09dVXl/r161eqrKwsnXzyyaWlS5cWMRXoVLtzLb37vbW140+/y+DDaHd/L/05YRxFKyuV/v+HRwEAAAAAHcoz4wAAAACgIMI4AAAAACiIMA4AAAAACiKMAwAAAICCCOMAAAAAoCDCOAAAAAAoiDAOAAAAAAoijAMAoBBlZWX5+c9/3tnDAADoVMI4AIC9wPnnn5+ysrItjlNOOaWzhwYAsFfp2tkDAACgGKecckp+9KMftSurrKzspNEAAOyd7IwDANhLVFZWpra2tt1RU1OT5J1bSGfPnp3Pfvaz2XffffORj3wkP/3pT9td/9RTT+Uv//Ivs++++6ZPnz656KKL8uabb7ar88Mf/jBHHnlkKisr079//1x22WXtzr/22ms5/fTT07179xx++OG5995728794Q9/yDnnnJP9998/++67bw4//PAtwkMAgA86YRwAAEmSq6++OmeeeWaeeOKJnHPOOfnSl76U5557Lkmybt26jB49OjU1NXn88cdz11135aGHHmoXts2ePTuXXnppLrroojz11FO59957c9hhh7Xr45prrsnZZ5+dJ598Mp/73Odyzjnn5PXXX2/r/9lnn82vfvWrPPfcc5k9e3b69u1b3C8AAKAAZaVSqdTZgwAAoGOdf/75+clPfpJu3bq1K/+7v/u7/N3f/V3Kyspy8cUXZ/bs2W3nPvnJT+bYY4/N97///dx6662ZMGFCVqxYkR49eiRJfvnLX+bzn/98Vq5cmX79+uXAAw/MBRdckL//+7/f6hjKysryrW99K9ddd12SdwK+nj175le/+lVOOeWUnHrqqenbt29++MMfdtBvAQCg83lmHADAXuKkk05qF7YlSe/evdt+HjlyZLtzI0eOzJIlS5Ikzz33XAYPHtwWxCXJpz/96bS2tmbp0qUpKyvLypUrc/LJJ293DEcffXTbzz169EhVVVXWrFmTJPmf//N/5swzz8zixYszatSonHbaafnUpz61S3MFANhTCeMAAPYSPXr02OK20d1l33333aF6++yzT7vPZWVlaW1tTZJ89rOfzbJly/LLX/4yDz74YE4++eRceumlueGGG3b7eAEAOotnxgEAkCT53e9+t8XnQYMGJUkGDRqUJ554IuvWrWs7/+ijj6a8vDwf+9jHst9++2XgwIGZN2/e+xrD/vvvn3HjxuUnP/lJZs6cmX/8x398X+0BAOxp7IwDANhLbNy4MY2Nje3Kunbt2vaShLvuuivDhg3L8ccfn9tvvz0LFy7MP/3TPyVJzjnnnEyePDnjxo3LlClT8uqrr+byyy/Peeedl379+iVJpkyZkosvvjgHHHBAPvvZz+aNN97Io48+mssvv3yHxjdp0qQMHTo0Rx55ZDZu3Jj77ruvLQwEAPiwEMYBAOwl5s6dm/79+7cr+9jHPpbnn38+yTtvOp0zZ04uueSS9O/fP//yL/+Sj3/840mS7t275/7778//+l//K8cdd1y6d++eM888MzfeeGNbW+PGjcuGDRvyne98J1deeWX69u2bs846a4fHV1FRkYkTJ+all17KvvvumxNOOCFz5szZDTMHANhzeJsqAAApKyvLPffck9NOO62zhwIA8KHmmXEAAAAAUBBhHAAAAAAUxDPjAACIJ5cAABTDzjgAAAAAKIgwDgAAAAAKIowDAAAAgIII4wAAAACgIMI4AAAAACiIMA4AAAAACiKMAwAAAICCCOMAAAAAoCDCOAAAAAAoyP8Hnwvztuzl4EgAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute predictions for true test set\n",
        "thresholds_full = [0.5]*18\n",
        "test_pred_full = test(model_full, device, test_dataloader,loss_full,thresholds=thresholds_full,target_available=False,predict_all=True)\n",
        "test_pred_full_predict_all_false = test(model_full, device, test_dataloader,loss_full,thresholds=thresholds_full,target_available=False,predict_all=False)"
      ],
      "metadata": {
        "id": "fgXokfW7pKbr",
        "outputId": "ba503417-06a1-4f05-e852-c3b15c42e28a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "fgXokfW7pKbr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:45<00:00, 221.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predictions computed for test set.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:45<00:00, 221.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predictions computed for test set.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save full model, check size and get predictions"
      ],
      "metadata": {
        "id": "bJUkISeQP1-w"
      },
      "id": "bJUkISeQP1-w"
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert predictions to csv\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "#test_pred_full = test(model_full, device, test_dataloader,loss,thresholds=thresholds_full,target_available=False)\n",
        "#print(test_pred_full)\n",
        "\n",
        "def get_class(array):\n",
        "  class_pred = np.where(array > 0.5)[1] + 1\n",
        "  for i in range(len(class_pred)):\n",
        "    if class_pred[i] >= 12:\n",
        "      class_pred += 1\n",
        "  return class_pred\n",
        "\n",
        "def unencode(y_pred,to_cpu=True):\n",
        "  labels = []\n",
        "  for i in range(len(y_pred)):\n",
        "    if to_cpu: # Move to cpu device\n",
        "      temp = y_pred[i].cpu()\n",
        "    temp = np.asarray(temp)\n",
        "    temp = get_class(temp)\n",
        "    temp = \" \".join(str(item) for item in temp)\n",
        "    labels.append(temp)\n",
        "  return labels\n",
        "\n",
        "# Save full model\n",
        "path_name_model = \"/content/model_\" + model_name + \"_full.pt\"\n",
        "path_name_plot = \"/content/model_\" + model_name + \"_losscurve_full.png\"\n",
        "\n",
        "torch.save(model_full.state_dict(), path_name_model)\n",
        "print(f\"Full Model saved to {path_name_model}\")\n",
        "size_mb = os.path.getsize(path_name_model) / (1024 * 1024)\n",
        "print(f\"Full Model size: {size_mb} MB\")\n",
        "\n",
        "plt.figure(figsize=(15,4))\n",
        "plt.plot(train_losses_full,label=\"Training\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.savefig(path_name_plot)\n",
        "\n",
        "#Save predictions in csv\n",
        "pred_labels = unencode(test_pred_full_predict_all_false)\n",
        "pred_df = df_test.copy()\n",
        "pred_df = pred_df.drop(\"Caption\",axis=1)\n",
        "pred_df[\"Labels\"] = pred_labels\n",
        "print(\"Submission dataframe:\")\n",
        "print(pred_df.describe)\n",
        "submission_name = \"/content/submission.csv\"\n",
        "pred_df.to_csv(submission_name,index=False)\n",
        "print(f\"Predictions saved as {submission_name}\")"
      ],
      "metadata": {
        "id": "zcZSgKoG5KtF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "outputId": "c7b0c2b9-f1d0-4bbe-ccaf-1e140cf9dd5f",
        "collapsed": true
      },
      "id": "zcZSgKoG5KtF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Model saved to /content/model_24_05_25_two_hidden_full.pt\n",
            "Full Model size: 3.243013381958008 MB\n",
            "Submission dataframe:\n",
            "<bound method NDFrame.describe of         ImageID Labels\n",
            "0     30000.jpg      1\n",
            "1     30001.jpg      1\n",
            "2     30002.jpg      1\n",
            "3     30003.jpg      1\n",
            "4     30004.jpg      1\n",
            "...         ...    ...\n",
            "9995  39995.jpg      1\n",
            "9996  39996.jpg  1 3 4\n",
            "9997  39997.jpg      1\n",
            "9998  39998.jpg      1\n",
            "9999  39999.jpg      1\n",
            "\n",
            "[10000 rows x 2 columns]>\n",
            "Predictions saved as /content/submission_pred_all_false.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit predictions\n",
        "! kaggle competitions submit -c multi-label-classification-competition-2025 -f /content/submission.csv -m \"More complex CNN without pred all\""
      ],
      "metadata": {
        "id": "jPrAkup83tGG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7594882e-f9ec-4a1e-8e9d-e6dae57b23bb"
      },
      "id": "jPrAkup83tGG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 120k/120k [00:00<00:00, 125kB/s]\n",
            "Successfully submitted to Multi-label Classification Competition 2025"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}